---
title: Is AI dangerous?
draft: true
description: Some thoughts on AI threats, open source and what to study
tags:
  - Philosophy
date: 2023-07-21
categories:
  - AI
authors:
  - ksaaskil
---

# Is AI dangerous?

_A man who is not afraid of the sea will soon be drowned, he said, for he will be going out on a day he shouldn't. But we do be afraid of the sea, and we do only be drownded now and again._ -John Millington Synge

<!-- more -->

The release of ChatGPT made the general public aware of large language models (LLMs). Pre-trained models like [GPT-4](https://openai.com/research/gpt-4) have [stunned researchers](https://arxiv.org/abs/2303.12712) by their better-than-human performance in tasks requiring deductive reasoning. LLMs do not just parrot the information they have learned but are able to combine it in novel ways.

LLMs fall under the larger umbrella of [foundation models](https://www.adalovelaceinstitute.org/resource/foundation-models-explainer/) (FMs). Foundation models are models pre-trained to handle specific tasks such as text-to-text or text-to-image generation. The datasets used to train these models are absolutely massive: training FMs from scratch on internet-scale datasets is in reach only for tech giants.

In March 2023, Future of Life institute published the open letter called [_Pause Giant AI Experiments_](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) that was signed by technology leaders such as Yoshua Bengio, Steve Wozniak, Stuart Russell and, yes, the infamous Elon Musk. The letter called for "_all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4_". The letter went on to say that "_AI labs and independent experts should use this pause to jointly develop and implement a set of shared safety protocols for advanced AI design and development that are rigorously audited and overseen by independent outside experts._"

The letter initiated a good and healthy discussion about the dangers of AI among the AI community. Industry leaders like Yann LeCun and Andrew Ng [opposed](https://www.youtube.com/watch?v=BY9KV8uCtj4) the call. However, I have also been somewhat disappointed to see the letter being dismissed either as a misunderstanding of how current AI systems work, as Elon Musk's marketing gimmick, or as an attempt to slow down competition.

For example, the Finnish Mikrobitti magazine recently described the letter as a warning about a conscious superbeing turning against humanity. Given that the article had just explained how LLMs are nothing more than text-to-text generators, this made the letter look ridiculous. How could a simple text-to-text generator become conscious?

I don't know if the author had even read the letter, but to me, this misunderstanding is a good example of the power of science fiction. Try googling for images with "AI existential threat" and you'll find pictures of menacing human-like robots that look like the Terminator.

What did the letter then warn us about?

Sam Altman, the CEO of OpenAI, was [interviewed by ABC News](https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122) in March 2023. He's not worried of omnipotent superbeing taking control: _"A common sci-fi fear that Altman doesn't share: AI models that don't need humans, that make their own decisions and plot world domination._" However, he is worried of which humans will be in control of these powerful AI systems.

Consider that you're an unpopular dictator waging war against a neighbor country. You have eliminated almost all of your skilled generals in fear of a coup. You lack skilled strategists and you are given the opportunity to let an AI system take control of your troops such as autonomous drones. Sometimes the system makes bad mistakes that leads to the deaths of a lot of soldiers, but that's a price you're willing to pay. What would stop you from trying it out?

## Case of Meta

## Disinformation: Robot calls, spam, deep fakes and all that

## Plugins allow FMs to interact with our world
